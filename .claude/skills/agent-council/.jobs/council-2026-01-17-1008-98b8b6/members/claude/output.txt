# 음성 인식 프롬프터 프로젝트 기술 자문

## 1) 추천 기술 스택과 아키텍처

### 프론트엔드 (권장: Electron + React 또는 Tauri + React)

| 옵션 | 장점 | 단점 |
|------|------|------|
| **Electron** | 풍부한 생태계, 크로스 플랫폼, 웹 기술 활용 | 메모리 사용량 높음 |
| **Tauri** | 경량, 빠름, Rust 기반 보안성 | 상대적으로 새로운 프레임워크 |
| **네이티브 (Swift/C#)** | 최적의 성능 | 플랫폼별 개발 필요 |

**권장**: Tauri + React/TypeScript
- 프롬프터는 단일 화면 앱이므로 Tauri의 경량성이 유리
- React로 반응형 UI 구현 용이

### 음성 인식 엔진

| 옵션 | 특징 | 비용 |
|------|------|------|
| **Web Speech API** | 브라우저 내장, 간단 | 무료 (온라인 필요) |
| **Whisper (OpenAI)** | 높은 정확도, 로컬 실행 가능 | 무료 (오픈소스) |
| **Vosk** | 오프라인, 경량, 다국어 | 무료 (오픈소스) |
| **Google Cloud STT** | 최고 수준 정확도 | 유료 |

**권장**: Whisper.cpp 또는 Vosk
- 오프라인 지원으로 촬영 현장에서 인터넷 불필요
- Whisper는 한국어 인식 정확도가 높음

### 아키텍처 다이어그램

```
┌─────────────────────────────────────────────────────┐
│                    Tauri App                        │
├─────────────────────────────────────────────────────┤
│  ┌─────────────┐    ┌─────────────┐    ┌─────────┐ │
│  │   React UI  │◄───│ State Mgmt  │◄───│ IPC     │ │
│  │  (프롬프터)  │    │  (Zustand)  │    │ Bridge  │ │
│  └─────────────┘    └─────────────┘    └────┬────┘ │
├─────────────────────────────────────────────┼──────┤
│  Rust Backend                               │      │
│  ┌─────────────┐    ┌─────────────┐    ┌───┴────┐ │
│  │   Whisper   │───►│  Text Match │───►│ Scroll │ │
│  │   Engine    │    │   Engine    │    │ Control│ │
│  └──────┬──────┘    └─────────────┘    └────────┘ │
│         │                                          │
│  ┌──────┴──────┐                                   │
│  │ Audio Input │                                   │
│  │  (cpal)     │                                   │
│  └─────────────┘                                   │
└─────────────────────────────────────────────────────┘
```

---

## 2) 음성 인식과 텍스트 매칭 알고리즘

### 핵심 과제
인식된 음성 텍스트와 대본의 **퍼지 매칭(Fuzzy Matching)** 필요
- 음성 인식 오류 허용
- 발화자가 대본을 정확히 따르지 않을 수 있음

### 추천 알고리즘

#### 1. Sliding Window + Levenshtein Distance
```
대본: "안녕하세요 오늘 영상에서는 프롬프터 개발에 대해 알아보겠습니다"

인식된 음성: "안녕하세요 오늘 영상에서"

[윈도우 슬라이딩]
Window 1: "안녕하세요 오늘 영상에서는" → 유사도 85% ✓
Window 2: "오늘 영상에서는 프롬프터" → 유사도 40%
...

→ 가장 높은 유사도 위치로 스크롤
```

#### 2. N-gram 기반 매칭
- 연속된 N개의 단어/음절을 비교
- 부분 일치에 강함

#### 3. 동적 시간 워핑 (DTW) 변형
- 음성의 속도 변화에 대응
- 발화 순서가 약간 바뀌어도 추적 가능

### 구현 시 핵심 로직

```typescript
interface MatchResult {
  position: number;      // 대본 내 현재 위치 (문자 인덱스)
  confidence: number;    // 매칭 신뢰도 (0-1)
  matchedText: string;   // 매칭된 대본 부분
}

function findBestMatch(
  script: string,           // 전체 대본
  recognizedText: string,   // 인식된 음성 텍스트
  lastPosition: number,     // 마지막 확인된 위치
  windowSize: number = 100  // 검색 범위
): MatchResult {
  // 1. 마지막 위치 근처에서 우선 검색 (효율성)
  // 2. N-gram 생성 및 비교
  // 3. 편집 거리 계산으로 최적 매칭 찾기
  // 4. 신뢰도 임계값 이하면 스크롤 유지
}
```

### 매칭 전략 팁

1. **전처리**: 숫자→한글 변환, 특수문자 제거, 정규화
2. **음절 단위 비교**: 한국어는 음절 기반이 효과적
3. **컨텍스트 유지**: 갑작스러운 점프 방지를 위해 이전 위치 기반 가중치
4. **신뢰도 임계값**: 낮은 신뢰도일 때 스크롤 멈춤

---

## 3) UI/UX 고려사항

### 필수 UI 요소

```
┌────────────────────────────────────────────────────┐
│ [설정] [대본 불러오기] [마이크 선택]        [녹화 모드] │
├────────────────────────────────────────────────────┤
│                                                    │
│                                                    │
│          지금 읽고 있는 문장이 여기에               │
│          크게 표시됩니다                            │
│                                                    │ ← 현재 위치
│   ─────────────────────────────────────────────   │
│                                                    │
│          다음에 읽을 내용이 여기에                  │
│          미리 보입니다                              │
│                                                    │
│                                                    │
├────────────────────────────────────────────────────┤
│ 인식: "지금 읽고 있는 문장이..."  [신뢰도: 92%]     │
└────────────────────────────────────────────────────┘
```

### 핵심 UX 원칙

| 항목 | 설명 |
|------|------|
| **부드러운 스크롤** | 갑작스러운 점프 대신 ease-in-out 애니메이션 |
| **현재 위치 강조** | 읽고 있는 부분 하이라이트 또는 확대 |
| **거울 모드** | 빔 프로젝터용 좌우 반전 옵션 |
| **고대비 모드** | 검정 배경 + 흰색/노란색 텍스트 |
| **폰트 크기 조절** | 촬영 거리에 따른 실시간 조절 |
| **수동 오버라이드** | 키보드/리모컨으로 수동 스크롤 가능 |

### 촬영 현장 특화 기능

1. **전체화면 모드**: 불필요한 UI 숨김
2. **카운트다운 타이머**: 촬영 시작 전 대기
3. **섹션 마커**: 대본을 구간별로 나누어 점프 가능
4. **되감기 제스처**: 잘못 인식 시 빠른 복귀
5. **외부 디스플레이 지원**: 촬영자용/연기자용 별도 화면

---

## 4) 잠재적 기술적 도전과 해결책

### 도전 1: 음성 인식 지연 (Latency)

**문제**: 실시간 인식이 0.5-2초 지연될 수 있음

**해결책**:
- 스트리밍 인식 사용 (중간 결과 활용)
- 예측 스크롤: 말하는 속도 분석 후 선제적 이동
- 버퍼링 전략: 짧은 오디오 청크(100-200ms) 단위 처리

### 도전 2: 배경 소음

**문제**: 촬영 현장의 다양한 소음

**해결책**:
- 노이즈 게이트 적용 (일정 볼륨 이하 무시)
- VAD (Voice Activity Detection) 적용
- 지향성 마이크 권장 사항 문서화
- RNNoise 같은 노이즈 제거 라이브러리 통합

### 도전 3: 대본 이탈/애드립

**문제**: 발화자가 대본과 다르게 말할 때

**해결책**:
```
[전략 1: 유사 구문 건너뛰기]
대본: "A → B → C → D"
발화: "A → D" (B, C 건너뜀)
→ D 위치로 자동 점프

[전략 2: 대기 모드]
신뢰도 < 50%가 3초 이상 지속
→ 스크롤 일시 정지 + 시각적 표시
→ 다시 매칭되면 재개
```

### 도전 4: 동음이의어/유사 발음

**문제**: "개발"과 "계발", "기사"와 "기자" 등

**해결책**:
- 문맥 기반 가중치 부여
- 이전/이후 단어 함께 비교
- 사용자 사전 등록 기능

### 도전 5: 긴 대본 성능

**문제**: 대본이 길어지면 매칭 성능 저하

**해결책**:
- 검색 윈도우 제한: 현재 위치 ±500자만 검색
- 인덱싱: 대본을 청크로 나눠 사전 인덱싱
- Web Worker/별도 스레드에서 매칭 처리

---

## 개발 로드맵 제안

```
Phase 1: MVP (핵심 기능)
├── 대본 입력/편집
├── 기본 음성 인식 (Web Speech API)
├── 단순 텍스트 매칭
└── 수동 스크롤 + 자동 스크롤

Phase 2: 고도화
├── Whisper 통합 (오프라인)
├── 퍼지 매칭 알고리즘 개선
├── 프리셋 저장/불러오기
└── 외부 디스플레이 지원

Phase 3: 프로덕션
├── 성능 최적화
├── 다국어 지원
├── 클라우드 동기화
└── 리모컨/페달 입력 지원
```

---

## 추가 질문

구현을 진행하시려면 다음 사항을 알려주세요:

1. **타겟 플랫폼**: Windows만? Mac도? 웹 기반?
2. **오프라인 필수 여부**: 인터넷 없이 동작해야 하는지?
3. **예상 대본 길이**: 일반적인 사용 시나리오?
4. **기존 기술 스택 선호도**: 특정 언어/프레임워크 경험?
